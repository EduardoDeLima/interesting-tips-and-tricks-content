{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqax4ltoBCCtvmfObosj5R"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🐛 5 Game-Changing Tips for Debugging Jupyter Notebooks\n"
      ],
      "metadata": {
        "id": "fxnlocXS77Fg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've all been there—staring at a notebook with mysterious errors and no clear path forward. Here's how I've learned to debug more efficiently:\n",
        "\n",
        "1. Use %debug magic command\n",
        "When your cell throws an error, run %debug in the next cell. It drops you into an interactive debugger right at the point of failure. Game changer.\n",
        "\n",
        "2. Print strategically with display()\n",
        "Instead of cluttering your notebook with print statements, use display() to show DataFrames, images, and objects in a cleaner format. Add print statements at key checkpoints to trace your data flow.\n",
        "\n",
        "3. Restart kernel + run all cells regularly\n",
        "Hidden state is your enemy. Variables from previous runs can cause confusing behavior. Make it a habit to restart and run all cells to ensure reproducibility.\n",
        "\n",
        "4. Break complex cells into smaller ones\n",
        "If a cell has 50 lines of code, debugging becomes a nightmare. Split logic into smaller, testable chunks. Each cell should do one thing well.\n",
        "\n",
        "5. Use assert statements liberally\n",
        "Add assertions to validate your assumptions about data shapes, types, and values throughout your notebook. They catch issues early before they cascade.\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "amodi77Z8JDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🐛 Jupyter Notebook Debugging Workshop - Google Colab"
      ],
      "metadata": {
        "id": "y8r0FoVg8Bvd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYrgEcg23Ugo",
        "outputId": "2a64b6e4-60fc-4c78-d0a7-4fe9b3cb6574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ Setup complete! Ready to debug.\n"
          ]
        }
      ],
      "source": [
        "# @title Example 1: Post-Mortem Debugging with %debug\n",
        "# Install ipdb for enhanced debugging\n",
        "!pip install -q ipdb\n",
        "\n",
        "import ipdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"✓ Setup complete! Ready to debug.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code has a bug - run it and it will crash\n",
        "def calculate_average(numbers):\n",
        "    total = sum(numbers)\n",
        "    count = len(numbers)\n",
        "    return total / count\n",
        "\n",
        "data = [10, 20, 30, 40, 50]\n",
        "results = []\n",
        "\n",
        "for i in range(len(data) + 1):  # Bug: goes one index too far\n",
        "    # This will fail when i exceeds the list length\n",
        "    subset = data[i:]\n",
        "    avg = calculate_average(subset)  # Empty list causes division by zero\n",
        "    results.append(avg)\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "EOspq56W8T87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try these commands in the debugger:​\n",
        "\n",
        "# p scores - See the empty list\n",
        "# p len(scores) - Confirms it's 0\n",
        "# l - List code around the error\n",
        "# q - Quit the debugger\n",
        "# c - Continue\n",
        "\n",
        "%debug"
      ],
      "metadata": {
        "id": "9F6STu86EeH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Example 2: Automatic Debugging with %pdb\n",
        "# Turn on automatic debugging\n",
        "%pdb on\n",
        "\n",
        "def calculate_total(a, b):\n",
        "    # Bug: will cause division by zero\n",
        "    result = a / b\n",
        "    return result\n",
        "\n",
        "# This will automatically trigger the debugger\n",
        "total = calculate_total(10, 0)\n",
        "print(f\"Total: {total}\")"
      ],
      "metadata": {
        "id": "jzgcYgO5Ef3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Commands to try:​\n",
        "\n",
        "# p a\n",
        "# p b\n",
        "# p a/b\n",
        "# q - Quit"
      ],
      "metadata": {
        "id": "OE6Kq92jEpiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pdb off"
      ],
      "metadata": {
        "id": "85deeeGpEzuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958e1859-c1e7-42e6-a62c-d7b83fb01d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned OFF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Example 3: Strategic Breakpoints with ipdb.set_trace()\n",
        "import ipdb\n",
        "import numpy as np\n",
        "\n",
        "def train_model_pipeline(data):\n",
        "    \"\"\"A complex pipeline with multiple steps\"\"\"\n",
        "\n",
        "    # Step 1: Clean data\n",
        "    cleaned = data[data > 0]\n",
        "    print(f\"After cleaning: {len(cleaned)} items\")\n",
        "\n",
        "    # Step 2: Transform data\n",
        "    ipdb.set_trace(context=3)  # PAUSE HERE to inspect\n",
        "\n",
        "    transformed = np.log(cleaned)\n",
        "\n",
        "    # Step 3: Calculate statistics\n",
        "    mean = transformed.mean()\n",
        "    std = transformed.std()\n",
        "\n",
        "    ipdb.set_trace()  # PAUSE AGAIN to check results\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "# Run the pipeline\n",
        "raw_data = np.array([1, 2, 3, 4, 5, -1, 0, 10])\n",
        "mean, std = train_model_pipeline(raw_data)\n",
        "print(f\"Mean: {mean:.2f}, Std: {std:.2f}\")"
      ],
      "metadata": {
        "id": "smccwpapE2a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Example 4: Debugging DataFrames\n",
        "def analyze_sales(sales_df):\n",
        "    \"\"\"Analyze sales data with intentional bugs\"\"\"\n",
        "\n",
        "    # Bug: String in numeric column\n",
        "    sales_df['revenue'] = sales_df['price'] * sales_df['quantity']\n",
        "\n",
        "    ipdb.set_trace()  # Pause to inspect data types\n",
        "\n",
        "    # Bug: This will fail due to data type issues\n",
        "    total_revenue = sales_df['revenue'].sum()\n",
        "    avg_revenue = sales_df['revenue'].mean()\n",
        "\n",
        "    return total_revenue, avg_revenue\n",
        "\n",
        "# Create sample data with a hidden bug\n",
        "sales_data = pd.DataFrame({\n",
        "    'product': ['A', 'B', 'C'],\n",
        "    'price': [10, '20', 30],  # Bug: '20' is a string!\n",
        "    'quantity': [5, 3, 8]\n",
        "})\n",
        "\n",
        "result = analyze_sales(sales_data)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "JHbVV6--E5MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Example 5: Real-World Machine Learning Bug\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def prepare_ml_data(X, y):\n",
        "    \"\"\"Prepare data for ML model\"\"\"\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    ipdb.set_trace()  # Check shapes before scaling test set\n",
        "\n",
        "    # Bug: Common mistake - scaling before checking shapes\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "# Generate sample data\n",
        "X = np.random.rand(100, 5)\n",
        "y = np.random.randint(0, 2, 100)\n",
        "\n",
        "X_train, X_test, y_train, y_test = prepare_ml_data(X, y)\n",
        "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n"
      ],
      "metadata": {
        "id": "Zb9ZVwfFE7RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Example 6: Defensive Programming with assert\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_data(df: pd.DataFrame, feature_columns: list):\n",
        "    \"\"\"\n",
        "    Cleans and prepares data for modeling.\n",
        "    Uses assert to validate inputs.\n",
        "    \"\"\"\n",
        "\n",
        "    # Assert 1: Check if the input is a pandas DataFrame\n",
        "    assert isinstance(df, pd.DataFrame), f\"Input must be a pandas DataFrame, but got {type(df)}\"\n",
        "\n",
        "    # Assert 2: Check if required columns exist in the DataFrame\n",
        "    assert all(col in df.columns for col in feature_columns), \\\n",
        "        f\"Missing required columns. Expected {feature_columns}, but got {list(df.columns)}\"\n",
        "\n",
        "    # Assert 3: Check for no null values in key columns\n",
        "    assert df[feature_columns].notna().all().all(), \"Null values detected in feature columns.\"\n",
        "\n",
        "    # --- Main function logic starts here ---\n",
        "    print(\"✓ Assertions passed! Preprocessing data...\")\n",
        "\n",
        "    # Example processing\n",
        "    df['processed'] = df[feature_columns].sum(axis=1)\n",
        "    return df\n",
        "\n",
        "# ---\n",
        "# Scenario 1: Everything works correctly\n",
        "# ---\n",
        "good_data = pd.DataFrame({\n",
        "    'feature1': [1, 2, 3],\n",
        "    'feature2': [4, 5, 6],\n",
        "    'other_col': ['a', 'b', 'c']\n",
        "})\n",
        "features = ['feature1', 'feature2']\n",
        "\n",
        "try:\n",
        "    processed_df = preprocess_data(good_data, features)\n",
        "    print(\"Scenario 1: Success!\\n\")\n",
        "    print(processed_df.head())\n",
        "except AssertionError as e:\n",
        "    print(f\"Scenario 1: Failed with AssertionError: {e}\\n\")\n",
        "\n",
        "\n",
        "# ---\n",
        "# Scenario 2: Fails because of a missing column\n",
        "# ---\n",
        "bad_data = pd.DataFrame({\n",
        "    'feature1': [1, 2, 3],\n",
        "    # 'feature2' is missing\n",
        "    'other_col': ['a', 'b', 'c']\n",
        "})\n",
        "\n",
        "try:\n",
        "    preprocess_data(bad_data, features)\n",
        "except AssertionError as e:\n",
        "    print(f\"\\nScenario 2: Failed as expected.\\nAssertionError: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOTPXA2Gn7u7",
        "outputId": "4ac1d27b-dae4-4ece-d06f-1f3b0df9f247"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Assertions passed! Preprocessing data...\n",
            "Scenario 1: Success!\n",
            "\n",
            "   feature1  feature2 other_col  processed\n",
            "0         1         4         a          5\n",
            "1         2         5         b          7\n",
            "2         3         6         c          9\n",
            "\n",
            "Scenario 2: Failed as expected.\n",
            "AssertionError: Missing required columns. Expected ['feature1', 'feature2'], but got ['feature1', 'other_col']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Additional information\n",
        "# Quick reference for debugger commands\n",
        "commands = {\n",
        "    'Navigation': {\n",
        "        'n': 'Next line',\n",
        "        's': 'Step into function',\n",
        "        'c': 'Continue until breakpoint',\n",
        "        'r': 'Continue until return',\n",
        "    },\n",
        "    'Inspection': {\n",
        "        'p variable': 'Print variable value',\n",
        "        'pp variable': 'Pretty print variable',\n",
        "        'l': 'List code context',\n",
        "        'w': 'Show stack trace',\n",
        "        'a': 'Show function arguments',\n",
        "    },\n",
        "    'Control': {\n",
        "        'q': 'Quit debugger',\n",
        "        'h': 'Show help',\n",
        "        'h command': 'Help for specific command',\n",
        "    }\n",
        "}\n",
        "\n",
        "for category, cmds in commands.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    for cmd, desc in cmds.items():\n",
        "        print(f\"  {cmd:15} - {desc}\")"
      ],
      "metadata": {
        "id": "RH9unmm8E-M0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ffec406-d209-4e8a-a00e-eb99d8cc76ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Navigation:\n",
            "  n               - Next line\n",
            "  s               - Step into function\n",
            "  c               - Continue until breakpoint\n",
            "  r               - Continue until return\n",
            "\n",
            "Inspection:\n",
            "  p variable      - Print variable value\n",
            "  pp variable     - Pretty print variable\n",
            "  l               - List code context\n",
            "  w               - Show stack trace\n",
            "  a               - Show function arguments\n",
            "\n",
            "Control:\n",
            "  q               - Quit debugger\n",
            "  h               - Show help\n",
            "  h command       - Help for specific command\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Practice Challenge\n",
        "def mystery_bug(numbers):\n",
        "    \"\"\"Can you find and fix the bug?\"\"\"\n",
        "    result = []\n",
        "    for i in range(len(numbers)):\n",
        "        # Hidden bug in this logic\n",
        "        if numbers[i] > numbers[i+1]:\n",
        "            result.append(numbers[i])\n",
        "    return result\n",
        "\n",
        "# This will crash - use debugging to find out why!\n",
        "data = [5, 3, 8, 1, 9, 2]\n",
        "output = mystery_bug(data)\n",
        "print(output)\n",
        "\n",
        "#Hint: Use %debug after the crash or add ipdb.set_trace() before the loop!"
      ],
      "metadata": {
        "id": "VjHQ5Av4FAhE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}